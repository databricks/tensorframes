// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/config.proto

package org.tensorflow.framework;

public interface ConfigProtoOrBuilder extends
    // @@protoc_insertion_point(interface_extends:tensorflow.ConfigProto)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <code>map&lt;string, int32&gt; device_count = 1;</code>
   *
   * <pre>
   * Map from device type name (e.g., "CPU" or "GPU" ) to maximum
   * number of devices of that type to use.  If a particular device
   * type is not found in the map, the system picks an appropriate
   * number.
   * </pre>
   */
  java.util.Map<java.lang.String, java.lang.Integer>
  getDeviceCount();

  /**
   * <code>optional int32 intra_op_parallelism_threads = 2;</code>
   *
   * <pre>
   * The execution of an individual op (for some op types) can be
   * parallelized on a pool of intra_op_parallelism_threads.
   * 0 means the system picks an appropriate number.
   * </pre>
   */
  int getIntraOpParallelismThreads();

  /**
   * <code>optional int32 inter_op_parallelism_threads = 5;</code>
   *
   * <pre>
   * Nodes that perform blocking operations are enqueued on a pool of
   * inter_op_parallelism_threads available in each process.
   * 0 means the system picks an appropriate number.
   * Note that the first Session created in the process sets the
   * number of threads for all future sessions unless use_per_session_threads is
   * true.
   * </pre>
   */
  int getInterOpParallelismThreads();

  /**
   * <code>optional bool use_per_session_threads = 9;</code>
   *
   * <pre>
   * If true, use a new set of threads for this session rather than the global
   * pool of threads. Only supported by direct sessions.
   * If false, use the global threads created by the first session.
   * </pre>
   */
  boolean getUsePerSessionThreads();

  /**
   * <code>optional int32 placement_period = 3;</code>
   *
   * <pre>
   * Assignment of Nodes to Devices is recomputed every placement_period
   * steps until the system warms up (at which point the recomputation
   * typically slows down automatically).
   * </pre>
   */
  int getPlacementPeriod();

  /**
   * <code>repeated string device_filters = 4;</code>
   *
   * <pre>
   * When any filters are present sessions will ignore all devices which do not
   * match the filters. Each filter can be partially specified, e.g. "/job:ps"
   * "/job:worker/replica:3", etc.
   * </pre>
   */
  com.google.protobuf.ProtocolStringList
      getDeviceFiltersList();
  /**
   * <code>repeated string device_filters = 4;</code>
   *
   * <pre>
   * When any filters are present sessions will ignore all devices which do not
   * match the filters. Each filter can be partially specified, e.g. "/job:ps"
   * "/job:worker/replica:3", etc.
   * </pre>
   */
  int getDeviceFiltersCount();
  /**
   * <code>repeated string device_filters = 4;</code>
   *
   * <pre>
   * When any filters are present sessions will ignore all devices which do not
   * match the filters. Each filter can be partially specified, e.g. "/job:ps"
   * "/job:worker/replica:3", etc.
   * </pre>
   */
  java.lang.String getDeviceFilters(int index);
  /**
   * <code>repeated string device_filters = 4;</code>
   *
   * <pre>
   * When any filters are present sessions will ignore all devices which do not
   * match the filters. Each filter can be partially specified, e.g. "/job:ps"
   * "/job:worker/replica:3", etc.
   * </pre>
   */
  com.google.protobuf.ByteString
      getDeviceFiltersBytes(int index);

  /**
   * <code>optional .tensorflow.GPUOptions gpu_options = 6;</code>
   *
   * <pre>
   * Options that apply to all GPUs.
   * </pre>
   */
  boolean hasGpuOptions();
  /**
   * <code>optional .tensorflow.GPUOptions gpu_options = 6;</code>
   *
   * <pre>
   * Options that apply to all GPUs.
   * </pre>
   */
  org.tensorflow.framework.GPUOptions getGpuOptions();
  /**
   * <code>optional .tensorflow.GPUOptions gpu_options = 6;</code>
   *
   * <pre>
   * Options that apply to all GPUs.
   * </pre>
   */
  org.tensorflow.framework.GPUOptionsOrBuilder getGpuOptionsOrBuilder();

  /**
   * <code>optional bool allow_soft_placement = 7;</code>
   *
   * <pre>
   * Whether soft placement is allowed. If allow_soft_placement is true,
   * an op will be placed on CPU if
   *   1. there's no GPU implementation for the OP
   * or
   *   2. no GPU devices are known or registered
   * or
   *   3. need to co-locate with reftype input(s) which are from CPU.
   * </pre>
   */
  boolean getAllowSoftPlacement();

  /**
   * <code>optional bool log_device_placement = 8;</code>
   *
   * <pre>
   * Whether device placements should be logged.
   * </pre>
   */
  boolean getLogDevicePlacement();

  /**
   * <code>optional .tensorflow.GraphOptions graph_options = 10;</code>
   *
   * <pre>
   * Options that apply to all graphs.
   * </pre>
   */
  boolean hasGraphOptions();
  /**
   * <code>optional .tensorflow.GraphOptions graph_options = 10;</code>
   *
   * <pre>
   * Options that apply to all graphs.
   * </pre>
   */
  org.tensorflow.framework.GraphOptions getGraphOptions();
  /**
   * <code>optional .tensorflow.GraphOptions graph_options = 10;</code>
   *
   * <pre>
   * Options that apply to all graphs.
   * </pre>
   */
  org.tensorflow.framework.GraphOptionsOrBuilder getGraphOptionsOrBuilder();
}
